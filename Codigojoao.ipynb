{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "879b6477-1d0c-43a0-9c4c-e52952fa6502",
   "metadata": {},
   "source": [
    "## Ajuste Fino de um Modelo de IA Generativa para Tarefas de Pergunta e Respostas.\n",
    "\n",
    "Neste notebook, irei trabalhar com dados extraídos do site oficial da Secretaria de Estado de Desenvolvimento Social de Goiás, com o objetivo de ajustar um modelo pré-treinado para lidar com perguntas e respostas relacionadas aos programas e benefícios oferecidos pela secretária. Para se adequar com a nossa necessidade, o modelo passará por um processo de ajuste fino. Primeiramente, iremos realizar um ajuste fino (Fine Tune, em inglês) total, onde todas as camadas do modelo pré-treinado serão modificadas, e depois apresentaremos o método PEFT (Ajuste Fino Eficiente de Parâmetros) que gasta menos recursos computacionais, e modifica apenas algumas camadas do modelo, conseguindo assim que ele retenha o conhecimento que já tem e evite o esquecimento catastrófico. Ao final, avaliaremos a precisão dos  dois modelos ajustados e determinaremos sua adequação para as tarefas definidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6418db8-8344-4055-9abc-8365430be0f5",
   "metadata": {},
   "source": [
    "##### Baixando bibliotecas necessárias:\n",
    "\n",
    "- transformers : A bibilioteca Transformers pode ser entendida como uma ferramenta poderosa para trabalhar com Processamento de Linguagem Natural \n",
    "- Datasets :  A biblioteca Datasets, também desenvolvida pela Hugging Face, é uma coleção de conjuntos de dados prontos para uso em uma variedade de tarefas de processamento de linguagem natural (PLN) e aprendizado de máquina (ML).\n",
    "- Evaluate: Com essa biblioteca você ganha acesso a dezenas de métodos de avaliação para diferentes modelos, o que fdacilita a acilita a avaliação de modelos de machine learning e datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e25f18-da78-4879-965f-5d727b50cf69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.37.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: evaluate in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\joao.calmeida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#baixando arquivos necessários\n",
    "\n",
    "!pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d47deb33-9858-4276-a8b9-aefebc7e2a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando as funções importantes para o fione-tune\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForPreTraining, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset, Dataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8c306c-78f3-44b9-8e8f-d2648ede0656",
   "metadata": {},
   "source": [
    "##### Escolhendo o modelo\n",
    "é importante escolher qual modelo pre treinaido você quer escolher.\n",
    "\n",
    "iremos usar o bloom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4810dcd6-eac7-44cf-bde7-3398d9da8358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escolhendo o modelo para realizar \n",
    "model_name = \"bigscience/bloom-560m\"\n",
    "model = AutoModelForPreTraining.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a68d24-8b31-4422-838c-cc1ed2dafe4b",
   "metadata": {},
   "source": [
    "##### Preparando os dados\n",
    "\n",
    "Quando vamos realizar um Fine-Tune, antes de qualquer coisa, precisamos preparar os dados que serão utilizados para realizar o ajuste do modelo.\n",
    "\n",
    "Os dados utilizados neste algoritmo foram criados com base nos beneficios oferecidos pela Secretaria de Estado de Desenvolvimento Social de Goiás. Essas informações podem ser consultadas neste [link](\"https://goias.gov.br/social/#\").\n",
    "\n",
    "O arquivo na extensão .json que foi utilizado está disponivel para download neste [link]().\n",
    "\n",
    "Extrai as informações do arquivo e atribui á um dicionario\n",
    "\n",
    "Etiquetei cada prompt com o nome do programa correspondente para melhorar a identificação do programa que se refere cada pergunta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137e64b5-0b94-49a7-be28-dd83e1e0238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_por_programa = {} #criando um dicionario para receber as informações do arquivo json \"relacionados3.json\"\n",
    "\n",
    "# Carregar o arquivo JSON\n",
    "with open('relacionados3.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Percorrer cada programa no arquivo JSON\n",
    "for programa, lista_perguntas_respostas in data.items():\n",
    "    # Criar uma entrada para o programa no dicionário\n",
    "    dataset_por_programa[programa] = []\n",
    "    # Percorrer cada item (dicionário) etiquetar prompts e completions\n",
    "    for item in lista_perguntas_respostas:\n",
    "        dataset_por_programa[programa].append({'prompt': f\"{programa} : {item['prompt']}\", 'completion': item['completion']})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87bc583-b7e2-4271-ad28-ebe7bf8fc3ce",
   "metadata": {},
   "source": [
    "Neste código, estamos iterando sobre o dicionário e extraindo as perguntas e respostas para cada programa. Em seguida, estruturamos essas perguntas e respostas em pares e os adicionamos à lista perguntas_respostas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "664d3232-27b9-458a-8325-42ef75fbf801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Programa de Água e Energia : Pode explicar o que é o Programa de Água e Energia?', 'É um programa destinado a auxiliar no pagamento das tarifas de energia elétrica, água tratada e coleta de esgotamento sanitário.'), ('Programa de Água e Energia : Pode explicar o que é o Programa de Água e Energia?', 'Trata-se de um auxílio voltado para custear as despesas com energia elétrica, água tratada e coleta de esgoto.'), ('Programa de Água e Energia : Pode explicar o que é o Programa de Água e Energia?', 'Consiste em um suporte financeiro direcionado para ajudar nos gastos relacionados à energia elétrica, água tratada e coleta de esgoto.'), ('Programa de Água e Energia : Pode explicar o que é o Programa de Água e Energia?', 'O Auxílio destina-se a subsidiar as despesas com energia elétrica, água tratada e coleta de esgoto sanitário.'), ('Programa de Água e Energia : Pode explicar o que é o Programa de Água e Energia?', 'Este programa tem como objetivo oferecer assistência financeira para despesas como energia elétrica, água tratada e coleta de esgoto.')]\n"
     ]
    }
   ],
   "source": [
    "perguntas_respostas = []\n",
    "\n",
    "for programa, lista_perguntas in dataset_por_programa.items():\n",
    "    for pergunta_resposta in lista_perguntas:\n",
    "        pergunta = pergunta_resposta[\"prompt\"]\n",
    "        respostas = pergunta_resposta[\"completion\"]\n",
    "        for resposta in respostas:\n",
    "            # Adiciona o par pergunta-resposta à lista\n",
    "            perguntas_respostas.append((pergunta, resposta))\n",
    "\n",
    "print(perguntas_respostas[:5])  # Exibe os primeiros 5 pares pergunta-resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83a2078-dc08-4fd7-a69d-f8771baf9cf4",
   "metadata": {},
   "source": [
    "### Testando fazer com csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9309e53f-2987-45ac-9f8d-7d1f5f9b390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4305a9fd-7d78-45f5-9d76-5d92a0fed7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o arquivo CSV\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Dividir o conjunto de dados em conjuntos de treinamento e teste\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Salvar os conjuntos de treinamento e teste em novos arquivos CSV\n",
    "train_df.to_csv('treino.csv', index=False)\n",
    "test_df.to_csv('teste.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3341c6db-1341-43aa-80d4-94809f375cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = {\"train\": \"treino.csv\", \"test\":'teste.csv'}\n",
    "dataSetCompleto = load_dataset(\"csv\", data_files=data_file)\n",
    "\n",
    "#atribuindo a variavel dados de tewste e de treino\n",
    "\n",
    "treino = dataSetCompleto['train']\n",
    "teste = dataSetCompleto['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef9a3a14-e3bc-4b38-a635-5a0a99bb98da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['pergunta', 'resposta'],\n",
      "    num_rows: 2120\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a023626a-7246-4b94-b926-33c4ba938c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui criamos uma função para facilitar a tokenização\n",
    "\n",
    "def tokenizar(dados):\n",
    "    sequencia = dados[\"pergunta\"] + \" [SEP] \" + dados[\"resposta\"]\n",
    "    return tokenizer(sequencia, truncation=True, padding=\"max_length\", max_length=1000)\n",
    "\n",
    "#fale sobre o mecanimo de atenção e sobre usar tokenização conjunta ou não\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ae0bdda-cbe9-40e9-ab07-6455d3f00df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6210b1181694779ae9f6672eb4f235d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/531 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebf7182a32248439fdd31e8675f1c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2120 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Falar do que cada coisa faz --> map\n",
    "dataset_teste = teste.map(tokenizar)\n",
    "dataset_treino = treino.map(tokenizar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a7c72d2-9499-4e71-8f5f-af318adea229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['pergunta', 'resposta', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 531\n",
      "})\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de73526-e2e8-431f-a211-8437e40b856a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
